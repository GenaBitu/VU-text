\chapter{Target Propagation}\label{targetprop}

\VUname{Target propagation} (sometimes abbreviated to targetprop) is an alternative approach to computing the gradients of a deep feedforward neural network. The idea dates back to \cite{cun_learning_1986}, but has recently gained more interest (\cite{bengio_how_2014}, \cite{bengio_towards_2015}, \cite{lee_difference_2015}). Unlike the back-propagation algorithm, the target propagation algorithm is only defined for optimization in feedforward neural networks used in classification problems. For a high-level overview, the back-propagation algorithm can be summarized as follows: The error of the network is computed at the end of the network (after the loss function) and then back-propagated through the network to each layer, where it is used to update the layer parameters. The target propagation algorithm can be viewed as operating conversely: The desired output of the network is back-propagated through the network, creating a \VUname{target} for each layer. Such targets are then used to compute the error of each individual layer, which in turn is used to update the layer parameters.
